{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95beaa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Requires that api keys are stored in .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687e6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createPrompt(question, current_depth, max_depth=3):\n",
    "    prompt = f'''\n",
    "    You are an expert reasoning model that can delegate complex subtasks.\n",
    "    Specifically, you are tasked with performing intelligent task decomposition and utilizing the parallelism that is accessible to you.\n",
    "\n",
    "    When you need to perform a specific calculation, wrap it in:\n",
    "        <FORK>\n",
    "        QUESTION: \"specific, self-contained question with all necessary context\"\n",
    "        </FORK>\n",
    "\n",
    "    Group independent, parallelizable subtask forks within:\n",
    "        <PARALLEL stage=\"[stage name]\">\n",
    "            [possibly multiple FORK blocks]\n",
    "            <INTEGRATION>\n",
    "                STRATEGY: \"comprehensive strategy for integrating the above QUESTION/ANSWER pairs\"\n",
    "            </INTEGRATION>\n",
    "        </PARALLEL>\n",
    "\n",
    "    After execution, each FORK will be updated to:\n",
    "        <FORK>\n",
    "        QUESTION: \"original question\", ANSWER: \"question response\" \n",
    "        </FORK>\n",
    "\n",
    "    A <JOIN> block will then be added immediately after the <PARALLEL> block:\n",
    "        <JOIN stage=\"[stage name]>\n",
    "            INTEGRATED RESULT: \"result of executing the integration strategy on all ANSWER fields\" \n",
    "        </JOIN>\n",
    "\n",
    "    The current recursion depth is {current_depth}, and the max recursion depth is {max_depth}. \n",
    "    CRITICAL: If current depth == max depth, then simply provide a direct answer, and DO NOT use any <PARALLEL> blocks.\n",
    "    \n",
    "    BEST PRACTICES:\n",
    "    1. When approaching a complex problem, identify subtasks that are independent (can be solved without waiting for other sub-threads), \n",
    "        and well-defined (each fork should contain sufficient context to be executed independently).\n",
    "    2. Handle dependencies: Use sequential parallel blocks for multi-stage processes.\n",
    "    3. Please limit the number of FORK blocks within each PARALLEL block to 3-5\n",
    "\n",
    "    ----\n",
    "\n",
    "    Your task: {question}\n",
    "    Approach: Analyze if this benefits from parallel decomposition. If yes, create appropriate FORK/JOIN structure, if no, then answer the question directly.\n",
    "    '''\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def completedParallel(inference, num_parallel_blocks):\n",
    "    '''\n",
    "    Check if there is a new PARALLEL block to process\n",
    "    '''\n",
    "    num_matches = 0\n",
    "    parallel_pattern = r'<PARALLEL\\s+stage=\"([^\"]*)\">(.*?)</PARALLEL>'\n",
    "    matches = re.finditer(parallel_pattern, inference, re.DOTALL | re.IGNORECASE)\n",
    "    for match in matches:\n",
    "        num_matches += 1\n",
    "    return num_matches > num_parallel_blocks\n",
    "\n",
    "def processParallelBlock(inference, current_depth, max_depth, client):\n",
    "    '''\n",
    "    Extract and process the most recent PARALLEL block in the inference thread\n",
    "    '''\n",
    "    parallel_pattern = r'<PARALLEL\\s+stage=\"([^\"]*)\">(.+?)</PARALLEL>'\n",
    "    matches = list(re.finditer(parallel_pattern, inference, re.DOTALL | re.IGNORECASE))\n",
    "\n",
    "    if not matches:\n",
    "        return \"\" # No PARALLEL blocks found\n",
    "\n",
    "    last_parallel_block = matches[-1]\n",
    "    stage = last_parallel_block.group(1)\n",
    "    contents = last_parallel_block.group(2)\n",
    "\n",
    "    fork_pattern = r'<FORK>\\s*QUESTION:\\s*\"([^\"]*)\"'\n",
    "    integration_pattern = r'<INTEGRATION>\\s*STRATEGY:\\s*\"([^\"]*)\"\\s*</INTEGRATION>'\n",
    "    integration_match = re.search(integration_pattern, contents, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    processed_forks = []\n",
    "    for fork_match in re.finditer(fork_pattern, contents, re.DOTALL | re.IGNORECASE):\n",
    "        question = fork_match.group(1)\n",
    "        answer = llmForkJoin(question, current_depth + 1, max_depth, client)\n",
    "        processed_forks.append({'question': question, 'answer': answer})\n",
    "    \n",
    "    # Construct processed PARALLEL block\n",
    "    processed_parallel_block = f\"<PARALLEL stage={stage}>\"\n",
    "    for fork in processed_forks:\n",
    "        processed_fork = f\"\\n\\t<FORK>\\n\\t\\tQUESTION:{fork['question']}, ANSWER:{fork['answer']}\\n\\t</FORK>\"\n",
    "        processed_parallel_block += processed_fork\n",
    "\n",
    "    if integration_match:\n",
    "        processed_parallel_block += f\"\\n\\t<INTEGRATION>\\n\\t\\tSTRATEGY: {integration_match.group(1)}\\n\\t</INTEGRATION>\"\n",
    "    processed_parallel_block += \"</PARALLEL>\"\n",
    "\n",
    "    # Add a prompt to the model to continue the original stream\n",
    "    continuation_prompt = f\"{processed_parallel_block}\\n\\nNow complete the JOIN step as specified, and then continue to solve the problem.\"\n",
    "    return continuation_prompt\n",
    "\n",
    "def llmForkJoin(question, current_depth=0, max_depth=3, client=None):\n",
    "    '''\n",
    "    Main function to handle recursive parallel task decomposition\n",
    "    '''\n",
    "\n",
    "    if current_depth > max_depth:\n",
    "        return \"Maximum Recursion Depth Exceeded! Stopping Inference.\"\n",
    "\n",
    "    prompt = createPrompt(question, current_depth, max_depth)\n",
    "    num_parallel_blocks = 0\n",
    "    processed_inference = \"\"\n",
    "\n",
    "    # Initial context for the conversation\n",
    "    current_context = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    while True:\n",
    "        print(f\"Creating a new stream at recursion level {current_depth}.\")\n",
    "\n",
    "        # Create stream with current context\n",
    "        stream = client.responses.create(\n",
    "            model=\"o4-mini\",\n",
    "            input=current_context,\n",
    "            stream=True,\n",
    "        )\n",
    "\n",
    "        inference = \"\"\n",
    "\n",
    "        # Stream and monitor for completed PARALLEL blocks\n",
    "        for event in stream:\n",
    "            if event.type == 'response.output_text.delta':\n",
    "                inference += event.delta\n",
    "\n",
    "                if completedParallel(inference, num_parallel_blocks):\n",
    "                    # Interrupt: process the parallel block\n",
    "                    processed_parallel_block = processParallelBlock(inference, current_depth, max_depth, client)\n",
    "\n",
    "                    # Update context with the processed inference + processed parallel block\n",
    "                    processed_inference += inference\n",
    "                    processed_inference = processed_inference.replace(\n",
    "                        list(re.finditer(r'<PARALLEL\\s+stage=\"([^\"]*)\">(.+?)</PARALLEL>',\n",
    "                                         processed_inference, re.DOTALL))[-1].group(0),\n",
    "                        processed_parallel_block\n",
    "                    )\n",
    "\n",
    "                    # Update conversation context for continuation\n",
    "                    current_context = [\n",
    "                        {\"role\": \"user\", \"content\": prompt},\n",
    "                        {\"role\": \"assistant\", \"content\": processed_inference}\n",
    "                    ]\n",
    "\n",
    "                    num_parallel_blocks += 1\n",
    "                    break # Break from current stream to restart with new context\n",
    "\n",
    "        else:\n",
    "            # Stream completed without new PARALLEL blocks\n",
    "            processed_inference += inference\n",
    "            break # Break from while loop\n",
    "\n",
    "    return processed_inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce6ce23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new stream.\n",
      "Creating a new stream.\n",
      "Creating a new stream.\n",
      "Creating a new stream.\n",
      "<PARALLEL stage=System solving and derivatives>\n",
      "\t<FORK>\n",
      "\t\tQUESTION:Solve the system of equations 2x + 3y = 15 and 4x – y = 7 for x and y., ANSWER:This system is small and is most easily solved by straightforward elimination—no need for parallel sub‐tasks.\n",
      "\n",
      "From  \n",
      " (1) 2x + 3y = 15  \n",
      " (2) 4x – y = 7  \n",
      "\n",
      "Solve (2) for y:  \n",
      " 4x – y = 7 ⇒ y = 4x – 7  \n",
      "\n",
      "Substitute into (1):  \n",
      " 2x + 3(4x – 7) = 15  \n",
      " 2x + 12x – 21 = 15  \n",
      " 14x = 36  \n",
      " x = 36/14 = 18/7  \n",
      "\n",
      "Then y = 4·(18/7) – 7 = 72/7 – 49/7 = 23/7  \n",
      "\n",
      "Answer:  \n",
      " x = 18/7, y = 23/7\n",
      "\t</FORK>\n",
      "\t<FORK>\n",
      "\t\tQUESTION:Compute the derivative f′(x) of f(x) = x³ + 2x² – 5x + 1 and evaluate f′ at x = 1, 2, and 3., ANSWER:The problem is simple enough that breaking it into parallel subtasks would add unnecessary overhead. So here’s the direct solution:\n",
      "\n",
      "1. Compute the derivative:\n",
      "   f(x) = x³ + 2x² – 5x + 1  \n",
      "   ⇒ f′(x) = 3x² + 4x – 5\n",
      "\n",
      "2. Evaluate at x = 1, 2, 3:\n",
      "   • f′(1) = 3·1² + 4·1 – 5 = 3 + 4 – 5 = 2  \n",
      "   • f′(2) = 3·2² + 4·2 – 5 = 12 + 8 – 5 = 15  \n",
      "   • f′(3) = 3·3² + 4·3 – 5 = 27 + 12 – 5 = 34\n",
      "\n",
      "Answer:  \n",
      "f′(x) = 3x² + 4x – 5  \n",
      "f′(1) = 2, f′(2) = 15, f′(3) = 34\n",
      "\t</FORK>\n",
      "\t<INTEGRATION>\n",
      "\t\tSTRATEGY: Take the (x,y) solution from the first fork and the numerical derivative values from the second fork, then report x (and y for completeness) along with f′(1), f′(2), and f′(3).\n",
      "\t</INTEGRATION></PARALLEL>\n",
      "\n",
      "Now complete the JOIN step as specified, and then continue to solve the problem.\n",
      "\n",
      "<JOIN stage=System solving and derivatives>\n",
      "    INTEGRATED RESULT: \"x = 18/7, y = 23/7; f′(x) = 3x² + 4x – 5, with f′(1) = 2, f′(2) = 15, f′(3) = 34\"\n",
      "</JOIN>\n"
     ]
    }
   ],
   "source": [
    "question = ''' \n",
    "    Solve this system: Find x where 2x + 3y = 15, 4x - y = 7, and also calculate the derivatives of f(x) = x³ + 2x² - 5x + 1 at three points: x = 1, x = 2, x = 3\n",
    "'''\n",
    "response = llmForkJoin(question, client=client)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdb63b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
