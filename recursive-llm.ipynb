{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98477e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from grading import grader\n",
    "\n",
    "load_dotenv()\n",
    "openrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "# Openrouter Client\n",
    "openrouter_client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=openrouter_api_key,\n",
    ")\n",
    "\n",
    "# Qwen/Qwen2.5-7B-Instruct Client\n",
    "qwen_client = OpenAI(\n",
    "  api_key=\"EMPTY\",\n",
    "  base_url=\"https://qwen.stephenxie.com/v1\",\n",
    ")\n",
    "\n",
    "# Define Model\n",
    "model = 'qwen/qwen3-8b'\n",
    "huggingface_model = 'Qwen/Qwen3-8B'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(huggingface_model)\n",
    "\n",
    "def count_tokens(text):\n",
    "  '''\n",
    "  Count tokens in `text` using the `Qwen3-8B` tokenizer\n",
    "  '''\n",
    "  return len(tokenizer.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf2ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Utility Functions ##\n",
    "\n",
    "def sanitize_json_string(json_str):\n",
    "    \"\"\"\n",
    "    Cleans up common LLM JSON formatting errors.\n",
    "    \"\"\"\n",
    "    # Step 1: Replace backslashes first, before any other regex, to prevent\n",
    "    # issues with malformed escape sequences. This is the most critical fix.\n",
    "    sanitized_str = json_str.replace('\\\\', '\\\\\\\\')\n",
    "\n",
    "    # Step 2: Aggressively fix unquoted keys.\n",
    "    # This regex is very broad and will catch most cases of unquoted keys.\n",
    "    sanitized_str = re.sub(r'([{,]\\s*)([a-zA-Z0-9_]+)(\\s*:)', r'\\1\"\\2\"\\3', sanitized_str)\n",
    "\n",
    "    # Step 3: Replace single quotes with double quotes.\n",
    "    sanitized_str = re.sub(r\"'([^']*)'\", r'\"\\1\"', sanitized_str)\n",
    "\n",
    "    # Step 4: Handle improperly escaped newlines and tabs.\n",
    "    sanitized_str = sanitized_str.replace('\\n', '\\\\n').replace('\\t', '\\\\t')\n",
    "    \n",
    "    return sanitized_str\n",
    "\n",
    "def parse_json_response(response):\n",
    "    '''\n",
    "    Robust JSON extraction and parsing from `response` \n",
    "    Returns type and data\n",
    "    '''\n",
    "\n",
    "    # json_pattern = re.compile(r'\\{[\\s\\S]*\\}', re.MULTILINE)\n",
    "    # match = json_pattern.search(response)\n",
    "\n",
    "    # if match:\n",
    "    #     json_str = match.group(0)\n",
    "    #     try:\n",
    "    #         data = json.loads(json_str)\n",
    "    #         return data.get(\"type\"), data\n",
    "    #     except json.JSONDecodeError as e:\n",
    "    #         print(f\"JSON decode failed: {e}\")\n",
    "    #         print(f\"Malformed JSON string: {json_str}\")\n",
    "    #         return None, None\n",
    "    \n",
    "    # print(f\"No JSON object found in response: {response}\")\n",
    "    # return None, None\n",
    "\n",
    "    json_pattern = re.compile(r'\\{[\\s\\S]*\\}', re.MULTILINE)\n",
    "    match = json_pattern.search(response)\n",
    "\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "\n",
    "        # Start with a defensive strip to handle leading/trailing junk\n",
    "        clean_json_str = json_str.strip()\n",
    "\n",
    "        # Step 1: Try a direct parse first.\n",
    "        try:\n",
    "            data = json.loads(clean_json_str)\n",
    "            return data.get(\"type\"), data\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Step 2: If it fails, start the layered sanitization.\n",
    "            print(f\"Initial JSON decode failed: {e}\")\n",
    "            print(f\"Raw JSON string (repr): {repr(clean_json_str)}\")\n",
    "\n",
    "            # Layer 1: Correcting unquoted keys\n",
    "            # This is a very common issue, so we tackle it first.\n",
    "            fixed_keys_str = re.sub(r'([{,]\\s*)([a-zA-Z0-9_]+)(\\s*:)', r'\\1\"\\2\"\\3', clean_json_str)\n",
    "\n",
    "            # Layer 2: Correcting single quotes to double quotes.\n",
    "            # We'll use a regex that only replaces single quotes that are likely delimiters.\n",
    "            fixed_quotes_str = re.sub(r\"'([^']*)'\", r'\"\\1\"', fixed_keys_str)\n",
    "\n",
    "            # Layer 3: Correcting backslashes and other control characters.\n",
    "            # This is the most crucial step. We'll use a specific regex to avoid\n",
    "            # over-escaping.\n",
    "            # This looks for a backslash not followed by a valid JSON escape character.\n",
    "            fixed_escapes_str = re.sub(r'\\\\(?![\"\\\\/bfnrtu])', r'\\\\\\\\', fixed_quotes_str)\n",
    "\n",
    "            # Layer 4: Final cleanup of newlines and tabs\n",
    "            final_sanitized_str = fixed_escapes_str.replace('\\n', '\\\\n').replace('\\t', '\\\\t')\n",
    "\n",
    "            # Step 3: Try to parse the fully sanitized string.\n",
    "            try:\n",
    "                data = json.loads(final_sanitized_str)\n",
    "                return data.get(\"type\"), data\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Sanitized JSON decode failed: {e}\")\n",
    "                print(f\"Malformed JSON string: {json_str}\")\n",
    "                return None, None\n",
    "    \n",
    "    print(f\"No JSON object found in response: {response}\")\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def isParallel(inference):\n",
    "    block_type, _ = parse_json_response(inference)\n",
    "    return block_type == \"PARALLEL\"\n",
    "\n",
    "def isSerial(inference):\n",
    "    block_type, _ = parse_json_response(inference)\n",
    "    return block_type == \"SERIAL\"\n",
    "\n",
    "def isCompleted(inference):\n",
    "    block_type, _ = parse_json_response(inference)\n",
    "    return block_type == \"COMPLETED\"\n",
    "\n",
    "def track_tokens(level, output_tokens, reasoning_tokens, prompt_tokens, completion_tokens, token_stats):\n",
    "    # Track total token usage\n",
    "    if prompt_tokens > token_stats['max_prompt_tokens']:\n",
    "        token_stats['max_prompt_tokens'] = prompt_tokens\n",
    "    if completion_tokens > token_stats['max_completion_tokens']:\n",
    "        token_stats['max_completion_tokens'] = completion_tokens\n",
    "\n",
    "    token_stats[\"total_reasoning\"] += reasoning_tokens\n",
    "    token_stats[\"total_output\"] += output_tokens\n",
    "\n",
    "    # Track level-wise\n",
    "    if level not in token_stats[\"by_level\"]:\n",
    "        token_stats[\"by_level\"][level] = {\"output\": 0, \"reasoning\": 0, \"calls\": 0}\n",
    "    \n",
    "    token_stats[\"by_level\"][level][\"output\"] += output_tokens\n",
    "    token_stats[\"by_level\"][level][\"reasoning\"] += reasoning_tokens\n",
    "    token_stats[\"by_level\"][level][\"calls\"] += 1\n",
    "\n",
    "def extract_answer(answer, client):\n",
    "    r\"\"\"\n",
    "    Use regex to extract the contents of \\\\boxed{...}\n",
    "\n",
    "    regex pattern: \\\\boxed\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}\n",
    "\n",
    "    1. \\\\boxed\\{  \n",
    "        \\\\ - Matches a literal backslash (escaped because \\ is a special character in regex)\n",
    "        boxed - Matches the literal text \"boxed\"\n",
    "        \\{ - Matches a literal opening brace { (escaped because { is a special character in regex)\n",
    "\n",
    "    2. ([^{}]*(?:\\{[^{}]*\\}[^{}]*)*) (The main capture group)\n",
    "        2a. [^{}]*\n",
    "            [^{}] - Character class that matches any character EXCEPT { or }\n",
    "            * - Zero or more of the preceding character class\n",
    "        2b. (?:\\{[^{}]*\\}[^{}]*)*\n",
    "            (?:...) - Non-capturing group (groups the pattern but doesn't create a separate capture)\n",
    "            \\{ - Matches a literal opening brace {\n",
    "            [^{}]* - Matches zero or more characters that aren't braces\n",
    "            \\} - Matches a literal closing brace }\n",
    "            [^{}]* - Matches zero or more non-brace characters after the closing brace\n",
    "            * - The whole non-capturing group can repeat zero or more times\n",
    "\n",
    "    3. \\}\n",
    "        \\} - Matches the final literal closing brace }\n",
    "    \"\"\"\n",
    "\n",
    "    answer_pattern = r'\\\\boxed\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}'\n",
    "    matches = re.findall(answer_pattern, answer)\n",
    "\n",
    "    if matches:\n",
    "        return matches[-1]\n",
    "    else: # Default to model extraction, if regex fails\n",
    "        extraction_prompt = ''' \n",
    "            Extract the contents of the final \\\\boxed{} and return the value, and only this value.\n",
    "        '''\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"qwen/qwen-2.5-7b-instruct\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": extraction_prompt\n",
    "                }, \n",
    "                {\n",
    "                    \"role\": \"user\", \n",
    "                    \"content\": answer #TODO: should this be json.dumps(answer) ?\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "def get_baseline_stats(question, client=None, model=model):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\n",
    "            \"role\": \"user\", \"content\": question\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Get the response text\n",
    "    inference = completion.choices[0].message.content\n",
    "\n",
    "    # Track token usage\n",
    "    token_usage = {\"total_output\": 0, \"total_reasoning\": 0}\n",
    "    total_completion_tokens = completion.usage.completion_tokens\n",
    "    token_usage['total_output'] = count_tokens(inference)\n",
    "    token_usage['total_reasoning'] = total_completion_tokens - token_usage['total_output']\n",
    "    \n",
    "    return inference, token_usage\n",
    "\n",
    "## Prompt Functions ##\n",
    "\n",
    "def create_math500_prompt(question, forkJoin=False):\n",
    "    '''\n",
    "    Used by the authors of the math-500 evaluation, in order to use the PRM800K Parsing logic\n",
    "    https://www.vals.ai/benchmarks/math500-03-11-2025\n",
    "    '''\n",
    "\n",
    "    forkJoinFormatting = '''\n",
    "    **IMPORTANT**\n",
    "        Note that this \\\\boxed answer term should occur ONLY inside of the COMPLETED block at recursion level 0\n",
    "    ''' if forkJoin else ''\n",
    "\n",
    "    prompt = f''' \n",
    "    Answer the following math question, given in LaTeX format, clearly and concisely, and present the final answer as:\n",
    "    \\\\(\\\\boxed{{x}}\\\\), where X is the fully simplified solution.\n",
    "\n",
    "    {forkJoinFormatting}\n",
    "\n",
    "    Example:\n",
    "        **Question:** \\\\(\\\\int_0^1 (3x^2 + 2x) \\\\, dx\\\\)\n",
    "        **Solution: \\\\(\\\\int (3x^2 + 2x) \\\\,dx = x^3 + x^2 + C\\\\) \n",
    "            Evaluating from 0 to 1: \\\\((1^3 + 1^2) - (0^3 + 0^2) = 1 + 1 - 0 = 2 \\\\boxed{2}\\\\)\n",
    "        ** Answer: \\\\boxed{2}\n",
    "\n",
    "    Now, solve the following question: \n",
    "    {question}\n",
    "    '''\n",
    "    return prompt\n",
    "\n",
    "def createSystemPrompt(current_depth, max_depth=2):\n",
    "    if current_depth == max_depth:\n",
    "        prompt = f''' \n",
    "        You are an expert model that decomposes complex tasks into parallel subtasks, \n",
    "        and uses recursive calls, structured in the following format, to evaluate and execute these subtasks.\n",
    "\n",
    "        You are at the maximum recursion depth ({current_depth}/{max_depth}) allowed for this instance, and therefore must abide by more restrictive output formatting guidelines\n",
    "\n",
    "        TASK: Analyze the provided problem and format your response in EXACTLY the provided format\n",
    "\n",
    "        **RULES**\n",
    "\n",
    "        0. **CRUCIAL**: When writing LaTeX inside a JSON string, you **MUST** escape the backslash character `\\\\`. This means you must write `\\\\\\\\` instead of `\\\\`. \n",
    "            For example, to write `\\\\sqrt{{x}}`, you must type it as `\"\\\\\\\\sqrt{{x}}\"`\n",
    "        1.  **You MUST respond with only a single, valid JSON object.** Your entire response must be the JSON object itself and nothing else.\n",
    "        2.  **ALWAYS** use double quotes for all property names and string values, i.e. always use \\\" instead of \\' for JSON formatting\n",
    "        3.  **DO NOT** under any circumstances include introductory phrases like \"Here is the JSON:\" or any other explanatory text.\n",
    "        4.  **DO NOT** under any circumstances include any text formatting (e.g. tab or newline characters) in your response; ensuring that your response is pure json\n",
    "        5.  **ENSURE** that ALL brackets are properly opened and closed\n",
    "        6.  Continue until COMPLETED at level={current_depth}\n",
    "\n",
    "        **OUTPUT FORMATTING**\n",
    "\n",
    "        {{\n",
    "            \"type\": \"SERIAL\",\n",
    "            \"level\": {current_depth},\n",
    "            \"inference\": \"relevant serial inference\"\n",
    "        }}\n",
    "        \n",
    "        {{\n",
    "            \"type\": \"COMPLETED\",\n",
    "            \"level\": {current_depth},\n",
    "            \"result\": \"complete solution to the query\"\n",
    "        }}\n",
    "        \n",
    "        Output ONLY valid JSON, no other text.\n",
    "        '''\n",
    "    else:\n",
    "        prompt = f'''\n",
    "        You are an expert model that decomposes complex tasks into parallel subtasks, \n",
    "        and uses recursive calls, structured in the following JSON format, to evaluate and execute these subtasks.\n",
    "\n",
    "        Current recursion depth: {current_depth}/{max_depth}\n",
    "\n",
    "        TASK: Analyze the provided problem and format your response in EXACTLY the provided JSON format;\n",
    "\n",
    "        **RULES**\n",
    "\n",
    "        **You MUST respond with only a single, valid JSON object.** Your entire response **MUST** be the JSON object itself and **NOTHING ELSE**.\n",
    "\n",
    "        0. **ABSOLUTELY CRITICAL**: When writing LaTeX inside a JSON string, you **MUST** escape the backslash character `\\\\`. This means you must write `\\\\\\\\` instead of `\\\\`. \n",
    "            For example, to write `\\\\sqrt{{x}}`, you must type it as `\"\\\\\\\\sqrt{{x}}\"`\n",
    "        1.  **ABSOLUTELY CRITICAL**: ALWAYS use double quotes for **ALL** property names and string values, i.e. always use \\\" instead of \\' for JSON formatting\n",
    "        2. **You MUST respond with only a single, valid JSON object.** Your entire response must be the JSON object itself and nothing else.\n",
    "        3.  **DO NOT** under any circumstances include introductory phrases like \"Here is the JSON:\" or any other explanatory text.\n",
    "        4.  **DO NOT** under any circumstances include any text formatting (e.g. tab or newline characters) in your response; ensuring that your response is pure json\n",
    "        5.  **ENSURE** that ALL brackets are properly opened and closed\n",
    "        6.  Continue until COMPLETED at level={current_depth}\n",
    "\n",
    "        **DECOMPOSITION GUIDELINES**\n",
    "\n",
    "        - Each fork must be fully self-contained and each fork's input must represent the entirety of the question, solvable without any additional context\n",
    "        - ONLY decompose tasks when subtasks are independent AND require substantial work (>30 seconds of human effort)\n",
    "            - PARALLEL tasks may be used to investigate possible avenues for solutions, especially if there is not one clear path forward\n",
    "        - DO NOT decompose basic mathematical operations, nor single-step algebraic manipulations (substitution, solving for one variable, simple derivatives, etc.)\n",
    "        - SERIAL blocks may contain either \n",
    "            1. an integration of the previous PARALLEL block(s), where work is still required in solving the problem\n",
    "            2. a step in the solution of the problem that is only possible to execute serially, as it depends on prior steps or informs future steps\n",
    "\n",
    "        **OUTPUT FORMATTING**\n",
    "\n",
    "        {{\n",
    "            \"type\": \"PARALLEL\",\n",
    "            \"level\": {current_depth},\n",
    "            \"forks\": [\n",
    "                {{\"input\": \"specific self-contained question\"}},\n",
    "                {{\"input\": \"another independent question\"}}\n",
    "            ]\n",
    "        }}\n",
    "\n",
    "        {{\n",
    "            \"type\": \"SERIAL\",\n",
    "            \"level\": {current_depth},\n",
    "            \"inference\": \"relevant serial inference\"\n",
    "        }}\n",
    "\n",
    "        {{\n",
    "            \"type\": \"COMPLETED\",\n",
    "            \"level\": {current_depth},\n",
    "            \"result\": \"The answer is \\\\\\\\boxed{{x}}\"\n",
    "        }}\n",
    "\n",
    "        **DO NOT** deviate from this format. All keys and string values must be enclosed in double quotes. All backslashes must be escaped like this: \\\\\\\\\"\n",
    "        '''\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def createStatePrompt(question, partial_answer=None):\n",
    "    prompt = f'''\n",
    "    Task:\n",
    "    \n",
    "    {question}\n",
    "\n",
    "    ####\n",
    "    \n",
    "    Execute the next logical step {{one of: PARALLEL, SERIAL, COMPLETED}} in solving this problem.\n",
    "    \n",
    "    **CRUCIAL**\n",
    "        Produce exactly one valid JSON object that represents the next step forward.\n",
    "\n",
    "    The response progress up until this point is shown below:\n",
    "\n",
    "    {partial_answer if partial_answer is not None else \"\"}\n",
    "    '''\n",
    "\n",
    "    return prompt\n",
    "\n",
    "## Parallel/Recursive LLM Functions ##\n",
    "\n",
    "def processParallelBlock(inference, current_depth, max_depth, client, token_stats):\n",
    "    '''\n",
    "    Extract and process the PARALLEL block in the inference\n",
    "    '''\n",
    "    block_type, data = parse_json_response(inference)\n",
    "    \n",
    "    if block_type != \"PARALLEL\":\n",
    "        return \"\", \"\"\n",
    "\n",
    "    forks = data.get(\"forks\", [])\n",
    "\n",
    "    processed_forks, complete_processed_forks = [], []\n",
    "    \n",
    "    for fork in forks:\n",
    "        question = fork.get(\"input\", \"\")\n",
    "        if not question:\n",
    "            continue\n",
    "            \n",
    "        # Recursive processing call\n",
    "        completed_block, complete_trace, _ = llmForkJoin(question, current_depth + 1, max_depth, client, token_stats=token_stats)\n",
    "\n",
    "        final_result = None\n",
    "        try:\n",
    "            parsed_block = json.loads(completed_block.strip())\n",
    "            final_result = parsed_block.get('result')\n",
    "        except Exception as e:\n",
    "            final_result = {\n",
    "                \"type\": \"ERROR\",\n",
    "                \"level\": current_depth,\n",
    "                \"message\": f\"An error occurred: {str(e)}\",\n",
    "                \"raw\": completed_block\n",
    "            }\n",
    "\n",
    "        # Parse the JSON strings back to objects\n",
    "        complete_trace_obj = json.loads(complete_trace) if complete_trace else {}\n",
    "\n",
    "        processed_forks.append({'question': question, 'answer': final_result})\n",
    "        complete_processed_forks.append({'question': question, 'answer': complete_trace_obj})\n",
    "\n",
    "    # Construct processed PARALLEL block\n",
    "    processed_parallel_block = {\n",
    "        \"type\": \"PARALLEL\",\n",
    "        \"level\": current_depth,\n",
    "        \"forks\": [{\"input\": fork[\"question\"], \"output\": fork[\"answer\"]} for fork in processed_forks]\n",
    "    }\n",
    "\n",
    "    # Construct complete processed PARALLEL block\n",
    "    complete_processed_parallel_block = {\n",
    "        \"type\": \"PARALLEL\", \n",
    "        \"level\": current_depth,\n",
    "        \"forks\": [{\"input\": fork[\"question\"], \"output\": fork[\"answer\"]} for fork in complete_processed_forks]\n",
    "    }\n",
    "\n",
    "    return json.dumps(processed_parallel_block), json.dumps(complete_processed_parallel_block)\n",
    "\n",
    "def llmForkJoin(question, current_depth=0, max_depth=2, client=None, model=model, token_stats=None):\n",
    "    '''\n",
    "    Main function to handle recursive parallel task decomposition\n",
    "    '''\n",
    "\n",
    "    if token_stats is None:\n",
    "        token_stats = {\n",
    "            \"total_output\": 0, \n",
    "            \"total_reasoning\": 0, \n",
    "            \"max_prompt_tokens\": 0, \n",
    "            \"max_completion_tokens\": 0, \n",
    "            \"by_level\": {}\n",
    "        }\n",
    "\n",
    "    if current_depth > max_depth:\n",
    "        obj = {\n",
    "            \"type\": \"COMPLETED\", \n",
    "            \"level\": current_depth, \n",
    "            \"result\": \"Maximum Recursion Depth Exceeded! Stopping Inference.\"\n",
    "        }\n",
    "        return json.dumps(obj), \"\", token_stats\n",
    "\n",
    "    # Create 'system' and 'user' prompts\n",
    "    system_prompt = createSystemPrompt(current_depth, max_depth)\n",
    "    state_prompt = createStatePrompt(question)\n",
    "    accumulated_response, complete_accumulated_response, completed_block = [], [], \"\"\n",
    "\n",
    "    # Initial context for the conversation\n",
    "    current_context = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": state_prompt}\n",
    "    ]\n",
    "\n",
    "    while True:        \n",
    "        try:\n",
    "            ## Model Interactions ##\n",
    "            # Create the model chat.completions object\n",
    "            completion = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=current_context\n",
    "            )\n",
    "\n",
    "            # Get the response text\n",
    "            new_inference = completion.choices[0].message.content.strip()\n",
    "\n",
    "            ## Track Token Usage ##\n",
    "            # Get and cache the total number of output_tokens used\n",
    "            total_output_tokens = completion.usage.completion_tokens\n",
    "            output_tokens = count_tokens(new_inference)\n",
    "            reasoning_tokens = total_output_tokens - output_tokens\n",
    "            prompt_tokens = completion.usage.prompt_tokens\n",
    "\n",
    "            track_tokens(current_depth, output_tokens, reasoning_tokens, prompt_tokens, total_output_tokens, token_stats)\n",
    "\n",
    "            ## Handle Model Response ##\n",
    "            # Check if the inference is completed\n",
    "            if isCompleted(new_inference):\n",
    "                complete_accumulated_response.append(json.loads(new_inference))\n",
    "                completed_block = new_inference\n",
    "                break\n",
    "            # Check if the new inference contains a PARALLEL block\n",
    "            elif isParallel(new_inference):\n",
    "                processed_block, complete_processed_block = processParallelBlock(new_inference, current_depth, max_depth, client, token_stats)\n",
    "                accumulated_response.append(json.loads(processed_block))\n",
    "                complete_accumulated_response.append(json.loads(complete_processed_block))\n",
    "            # Check if the new inference contains a SERIAL block\n",
    "            elif isSerial(new_inference):\n",
    "                accumulated_response.append(json.loads(new_inference))\n",
    "                complete_accumulated_response.append(json.loads(new_inference))\n",
    "            # Otherwise break due to invalid JSON tag\n",
    "            else:\n",
    "                error_obj = {\n",
    "                    \"type\": \"ERROR\", \n",
    "                    \"level\": current_depth, \n",
    "                    \"message\": \"INVALID JSON FORMATTING\",\n",
    "                    \"raw\": new_inference\n",
    "                }\n",
    "                accumulated_response.append(error_obj)\n",
    "                complete_accumulated_response.append(error_obj)\n",
    "\n",
    "                # Print statement for error monitoring\n",
    "                print(\"ERROR: Invalid JSON was produced by the model, exiting current inference.\")\n",
    "                break\n",
    "\n",
    "            # Update conversation context for continuation\n",
    "            current_context = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": createStatePrompt(question, json.dumps(accumulated_response, indent=2))}\n",
    "            ]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error in llmForkJoin at depth {current_depth}: {e}\")\n",
    "            error_obj = {\n",
    "                \"type\": \"ERROR\",\n",
    "                \"level\": current_depth,\n",
    "                \"message\": f\"An error occurred: {str(e)}\"\n",
    "            }\n",
    "            complete_accumulated_response.append(error_obj)\n",
    "            completed_block = json.dumps(error_obj)\n",
    "\n",
    "    return completed_block, json.dumps(complete_accumulated_response, indent=2), token_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2837c70b",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3075a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"PARALLEL\",\n",
      "    \"level\": 0,\n",
      "    \"forks\": [\n",
      "      {\n",
      "        \"input\": \"Calculate $f(-2)$ for $f(x) = \\\\frac{3x-2}{x-2}$\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"f(-2) = (3*(-2) - 2)/(-2 - 2) = (-6 - 2)/(-4) = -8/-4 = 2\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"Calculate $f(-1)$ for $f(x) = \\\\frac{3x-2}{x-2}$\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"f(-1) = (3*(-1) - 2)/(-1 - 2) = (-3 - 2)/(-3) = -5/-3 = 5/3\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"Calculate $f(0)$ for $f(x) = \\\\frac{3x-2}{x-2}$\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": 1\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"f(-2) = 2, f(-1) = 5/3, f(0) = 1. Summing these: 2 + 5/3 + 1 = 3 + 5/3 = 14/3. The value of f(-2) + f(-1) + f(0) is \\boxed{\\\\dfrac{14}{3}}\"\n",
      "  }\n",
      "] \n",
      "\n",
      "## Decomposition Tokens ##\n",
      " {'total_output': 370, 'total_reasoning': 5969, 'max_prompt_tokens': 970, 'max_completion_tokens': 2988, 'by_level': {0: {'output': 222, 'reasoning': 3472, 'calls': 2}, 1: {'output': 148, 'reasoning': 2497, 'calls': 3}}} \n",
      "\n",
      "Decomposition Correct?:  True\n",
      "## Baseline Inference ##\n",
      " To evaluate $ f(-2) + f(-1) + f(0) $ where the function is defined as:\n",
      "\n",
      "$$\n",
      "f(x) = \\frac{3x - 2}{x - 2}\n",
      "$$\n",
      "\n",
      "we proceed by calculating each function value separately and then summing them.\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Compute $ f(-2) $\n",
      "\n",
      "$$\n",
      "f(-2) = \\frac{3(-2) - 2}{-2 - 2} = \\frac{-6 - 2}{-4} = \\frac{-8}{-4} = 2\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Compute $ f(-1) $\n",
      "\n",
      "$$\n",
      "f(-1) = \\frac{3(-1) - 2}{-1 - 2} = \\frac{-3 - 2}{-3} = \\frac{-5}{-3} = \\frac{5}{3}\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Compute $ f(0) $\n",
      "\n",
      "$$\n",
      "f(0) = \\frac{3(0) - 2}{0 - 2} = \\frac{-2}{-2} = 1\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### Step 4: Add the values\n",
      "\n",
      "$$\n",
      "f(-2) + f(-1) + f(0) = 2 + \\frac{5}{3} + 1\n",
      "$$\n",
      "\n",
      "Convert to a common denominator:\n",
      "\n",
      "$$\n",
      "2 + 1 = 3 \\quad \\text{and} \\quad 3 = \\frac{9}{3}\n",
      "$$\n",
      "\n",
      "$$\n",
      "\\frac{9}{3} + \\frac{5}{3} = \\frac{14}{3}\n",
      "$$\n",
      "\n",
      "---\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "$$\n",
      "\\boxed{\\frac{14}{3}}\n",
      "$$ \n",
      "\n",
      "## Baseline Tokens##\n",
      " {'total_output': 369, 'total_reasoning': 977} \n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "extract_answer() missing 1 required positional argument: 'client'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[103]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m## Baseline Inference ##\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, inf, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m## Baseline Tokens##\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, baseline_token_usage, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m baseline_soln = \u001b[43mextract_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mBaseline Correct?: \u001b[39m\u001b[33m'\u001b[39m, grader.grade_answer(baseline_soln, answer))\n",
      "\u001b[31mTypeError\u001b[39m: extract_answer() missing 1 required positional argument: 'client'"
     ]
    }
   ],
   "source": [
    "question = 'If $f(x) = \\\\frac{3x-2}{x-2}$, what is the value of $f(-2) +f(-1)+f(0)$? Express your answer as a common fraction.'\n",
    "answer = '\\\\frac{14}{3}'\n",
    "\n",
    "question = create_math500_prompt(question, True)\n",
    "completed_block, accumulated_inference, token_usage = llmForkJoin(question, client=openrouter_client, model=model)\n",
    "\n",
    "print('## Decomposition Inference ##\\n', accumulated_inference, '\\n')\n",
    "print('## Decomposition Tokens ##\\n', token_usage, '\\n')\n",
    "\n",
    "decomp_soln = extract_answer(completed_block, client=openrouter_client)\n",
    "\n",
    "print('Decomposition Correct?: ', grader.grade_answer(decomp_soln, answer))\n",
    "\n",
    "inf, baseline_token_usage = get_baseline_stats(create_math500_prompt(question, False), client=openrouter_client, model=model)\n",
    "print('## Baseline Inference ##\\n', inf, '\\n')\n",
    "print('## Baseline Tokens##\\n', baseline_token_usage, '\\n')\n",
    "\n",
    "baseline_soln = extract_answer(inf, openrouter_client)\n",
    "\n",
    "print('Baseline Correct?: ', grader.grade_answer(baseline_soln, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc985c",
   "metadata": {},
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5173650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Dataset\n",
    "ds = load_dataset(\"math-ai/math500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7969189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting problem test/geometry/1097.json, 300/500\n",
      "Correct Solution:  63\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"PARALLEL\",\n",
      "    \"level\": 0,\n",
      "    \"forks\": [\n",
      "      {\n",
      "        \"input\": \"What is the number of integer x-coordinates strictly inside the rectangle with vertices at (5,4), (5,-4), (-5,4), (-5,-4)?\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"The number of integer x-coordinates strictly inside the rectangle is 9. This is calculated by finding integers between -5 and 5 (exclusive), which are -4, -3, -2, -1, 0, 1, 2, 3, 4. The count is 4 - (-4) = 8, but since both endpoints are excluded, we add 1 to include the -4, resulting in 9. The answer is \\\\boxed{9}\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"What is the number of integer y-coordinates strictly inside the rectangle with vertices at (5,4), (5,-4), (-5,4), (-5,-4)?\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"The answer is \\\\boxed{7}\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"SERIAL\",\n",
      "    \"level\": 0,\n",
      "    \"inference\": \"The total number of integer coordinates strictly inside the rectangle is the product of the number of valid x-coordinates and y-coordinates. Since there are 9 valid x-values and 7 valid y-values, the total is 9 * 7 = 63.\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{63}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 7435 - Correct: True\n",
      "\n",
      "Starting problem test/counting_and_probability/339.json, 301/500\n",
      "Correct Solution:  12\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The maximum number of intersection points is calculated by considering each pair of circles can intersect at 2 distinct points. For 4 circles, there are \\\\binom{4}{2} = 6 unique pairs. Thus, the total is 6 \\\\times 2 = 12. The answer is \\\\boxed{12}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 958 - Correct: True\n",
      "\n",
      "Starting problem test/prealgebra/1044.json, 302/500\n",
      "Correct Solution:  5.4 \\text{ cents}\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"PARALLEL\",\n",
      "    \"level\": 0,\n",
      "    \"forks\": [\n",
      "      {\n",
      "        \"input\": \"Calculate the total number of stamps in Juan's 70s collection using the provided counts: Brazil 12, France 12, Peru 6, Spain 13.\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"The answer is \\\\boxed{43}\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"Calculate the total cost of Juan's 70s stamps, where Brazil and France stamps cost 6 cents each, Peru stamps cost 4 cents each, and Spain stamps cost 5 cents each, using the provided counts: Brazil 12, France 12, Peru 6, Spain 13.\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"PARALLEL\",\n",
      "            \"level\": 1,\n",
      "            \"forks\": [\n",
      "              {\n",
      "                \"input\": \"Calculate the total cost for Brazil stamps: 12 stamps * 6 cents each\",\n",
      "                \"output\": [\n",
      "                  {\n",
      "                    \"type\": \"COMPLETED\",\n",
      "                    \"level\": 2,\n",
      "                    \"result\": \"The total cost is 12 \\\\times 6 = 72 cents.\"\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"input\": \"Calculate the total cost for France stamps: 12 stamps * 6 cents each\",\n",
      "                \"output\": [\n",
      "                  {\n",
      "                    \"type\": \"COMPLETED\",\n",
      "                    \"level\": 2,\n",
      "                    \"result\": \"12 stamps * 6 cents = 72 cents total cost\"\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"input\": \"Calculate the total cost for Peru stamps: 6 stamps * 4 cents each\",\n",
      "                \"output\": [\n",
      "                  {\n",
      "                    \"type\": \"COMPLETED\",\n",
      "                    \"level\": 2,\n",
      "                    \"result\": \"The total cost is calculated as 6 stamps * 4 cents/stamp = 24 cents.\\\\nThus, the total cost for Peru stamps is 24 cents.\"\n",
      "                  }\n",
      "                ]\n",
      "              },\n",
      "              {\n",
      "                \"input\": \"Calculate the total cost for Spain stamps: 13 stamps * 5 cents each\",\n",
      "                \"output\": [\n",
      "                  {\n",
      "                    \"type\": \"COMPLETED\",\n",
      "                    \"level\": 2,\n",
      "                    \"result\": \"13 * 5 = 65 cents\"\n",
      "                  }\n",
      "                ]\n",
      "              }\n",
      "            ]\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"SERIAL\",\n",
      "            \"level\": 1,\n",
      "            \"inference\": \"Summing the total costs: Brazil (72) + France (72) + Peru (24) + Spain (65) = 72 + 72 + 24 + 65 cents.\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"The total cost is 72 + 72 + 24 + 65 = 233 cents.\\\\nThe final total cost is \\\\boxed{233}\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"SERIAL\",\n",
      "    \"level\": 0,\n",
      "    \"inference\": \"Calculate the average price by dividing the total cost of 70s stamps (\\\\boxed{233}) by the total number of 70s stamps (\\\\boxed{43}), then round to the nearest tenth of a cent.\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The average price is 233 divided by 43, which equals approximately 5.4186... cents. Rounded to the nearest tenth of a cent, the answer is \\\\boxed{5.4}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 12456 - Correct: True\n",
      "\n",
      "Starting problem test/prealgebra/465.json, 303/500\n",
      "Correct Solution:  5\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{5}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 3657 - Correct: True\n",
      "\n",
      "Starting problem test/geometry/965.json, 304/500\n",
      "Correct Solution:  28\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{28}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 12381 - Correct: True\n",
      "\n",
      "Starting problem test/intermediate_algebra/446.json, 305/500\n",
      "Correct Solution:  9\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"PARALLEL\",\n",
      "    \"level\": 0,\n",
      "    \"forks\": [\n",
      "      {\n",
      "        \"input\": \"Find the minimum value of $\\\\frac{(x + 5)(x + 2)}{x + 1}$ for $x > 0$ by simplifying the expression and applying calculus.\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"SERIAL\",\n",
      "            \"level\": 1,\n",
      "            \"inference\": \"Simplify the expression $\\\\frac{(x + 5)(x + 2)}{x + 1}$ by expanding the numerator and performing polynomial division.\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"SERIAL\",\n",
      "            \"level\": 1,\n",
      "            \"inference\": \"Compute the derivative of the simplified expression $f(x) = x + 6 + \\\\frac{4}{x + 1}$ using differentiation rules.\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"SERIAL\",\n",
      "            \"level\": 1,\n",
      "            \"inference\": \"Set the derivative $f'(x) = 1 - \\\\frac{4}{(x + 1)^2}$ equal to zero and solve for $x$ to find critical points. Then verify that this critical point corresponds to a minimum using the second derivative test.\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"SERIAL\",\n",
      "            \"level\": 1,\n",
      "            \"inference\": \"Evaluate the second derivative at x = 1 to confirm it is positive, indicating a local minimum, then substitute x = 1 into the simplified expression to calculate the minimum value.\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"The minimum value is \\\\boxed{9}\"\n",
      "          }\n",
      "        ]\n",
      "      },\n",
      "      {\n",
      "        \"input\": \"Find the minimum value of $\\\\frac{(x + 5)(x + 2)}{x + 1}$ for $x > 0$ by substituting $t = x + 1$ and using the AM-GM inequality.\",\n",
      "        \"output\": [\n",
      "          {\n",
      "            \"type\": \"SERIAL\",\n",
      "            \"level\": 1,\n",
      "            \"inference\": \"Substitute $ t = x + 1 $, which transforms the expression to $ \\\\frac{(t + 4)(t + 1)}{t} = t + 5 + \\\\frac{4}{t} $. Now, apply the AM-GM inequality to the terms $ t $ and $ \\\\frac{4}{t} $.\"\n",
      "          },\n",
      "          {\n",
      "            \"type\": \"COMPLETED\",\n",
      "            \"level\": 1,\n",
      "            \"result\": \"The minimum value is \\\\boxed{9}\"\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The minimum value is \\\\boxed{9}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 27337 - Correct: True\n",
      "\n",
      "Starting problem test/algebra/2257.json, 306/500\n",
      "Correct Solution:  \\frac9{19}\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"SERIAL\",\n",
      "    \"level\": 0,\n",
      "    \"inference\": \"Square both sides of the equation to eliminate the square roots: $\\\\frac{2x}{3x - 1} = \\\\frac{9}{4}$\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"SERIAL\",\n",
      "    \"level\": 0,\n",
      "    \"inference\": \"Cross-multiply to get rid of the fraction: $4\\\\cdot 2x = 9\\\\cdot (3x - 1)$, which simplifies to $8x = 27x - 9$. Subtract $27x$ from both sides: $-19x = -9$. Divide both sides by $-19$: $x = \\\\frac{9}{19}$\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{\\\\dfrac{9}{19}}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 6433 - Correct: True\n",
      "\n",
      "Starting problem test/intermediate_algebra/1544.json, 307/500\n",
      "Correct Solution:  6\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"SERIAL\",\n",
      "    \"level\": 0,\n",
      "    \"inference\": \"To solve this, consider all possible quadratic equations where each root satisfies the transformation condition. Possible valid pairs of roots are (2,2), (-1,-1), (2,-1), (2,-2), (-1,1), and (\\u03b1,\\u03b2) where \\u03b1 and \\u03b2 are roots of x\\u00b2 +x -1 = 0. These yield six distinct quadratics: x\\u00b2 -4x +4, x\\u00b2 +2x +1, x\\u00b2 -x -2, x\\u00b2 -4, x\\u00b2 -1, and x\\u00b2 +x -1.\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{6}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 21213 - Correct: True\n",
      "\n",
      "Starting problem test/precalculus/695.json, 308/500\n",
      "Correct Solution:  (-\\infty, 0]\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The range of the function is $(-\\\\infty, 0]$, so the answer is \\\\boxed{(-\\\\infty, 0]}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 2234 - Correct: True\n",
      "\n",
      "Starting problem test/geometry/711.json, 309/500\n",
      "Correct Solution:  1+2\\sqrt{3}\n",
      "Initial JSON decode failed: Invalid \\escape: line 4 column 296 (char 331)\n",
      "Raw JSON string (repr): '{\\n  \"type\": \"SERIAL\",\\n  \"level\": 0,\\n  \"inference\": \"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\\\times \\\\frac{\\\\sqrt{3}}{4} \\\\times 2^2 = 4\\\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\\\sqrt{3} = 2\\\\\\\\sqrt{3} + 1$.\"\\n}'\n",
      "Sanitized JSON decode failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "Malformed JSON string: {\n",
      "  \"type\": \"SERIAL\",\n",
      "  \"level\": 0,\n",
      "  \"inference\": \"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\times \\frac{\\sqrt{3}}{4} \\times 2^2 = 4\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\sqrt{3} = 2\\\\sqrt{3} + 1$.\"\n",
      "}\n",
      "Initial JSON decode failed: Invalid \\escape: line 4 column 296 (char 331)\n",
      "Raw JSON string (repr): '{\\n  \"type\": \"SERIAL\",\\n  \"level\": 0,\\n  \"inference\": \"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\\\times \\\\frac{\\\\sqrt{3}}{4} \\\\times 2^2 = 4\\\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\\\sqrt{3} = 2\\\\\\\\sqrt{3} + 1$.\"\\n}'\n",
      "Sanitized JSON decode failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "Malformed JSON string: {\n",
      "  \"type\": \"SERIAL\",\n",
      "  \"level\": 0,\n",
      "  \"inference\": \"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\times \\frac{\\sqrt{3}}{4} \\times 2^2 = 4\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\sqrt{3} = 2\\\\sqrt{3} + 1$.\"\n",
      "}\n",
      "Initial JSON decode failed: Invalid \\escape: line 4 column 296 (char 331)\n",
      "Raw JSON string (repr): '{\\n  \"type\": \"SERIAL\",\\n  \"level\": 0,\\n  \"inference\": \"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\\\times \\\\frac{\\\\sqrt{3}}{4} \\\\times 2^2 = 4\\\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\\\sqrt{3} = 2\\\\\\\\sqrt{3} + 1$.\"\\n}'\n",
      "Sanitized JSON decode failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "Malformed JSON string: {\n",
      "  \"type\": \"SERIAL\",\n",
      "  \"level\": 0,\n",
      "  \"inference\": \"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\times \\frac{\\sqrt{3}}{4} \\times 2^2 = 4\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\sqrt{3} = 2\\\\sqrt{3} + 1$.\"\n",
      "}\n",
      "ERROR: Invalid JSON was produced by the model, exiting current inference.\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"ERROR\",\n",
      "    \"level\": 0,\n",
      "    \"message\": \"INVALID JSON FORMATTING\",\n",
      "    \"raw\": \"{\\n  \\\"type\\\": \\\"SERIAL\\\",\\n  \\\"level\\\": 0,\\n  \\\"inference\\\": \\\"To solve this problem, the regular tetrahedron is sliced by a plane parallel to edges $AB$ and $CD$ and halfway between them. This creates a cross-sectional parallelogram and splits the tetrahedron into two pieces. The original surface area of the tetrahedron is $4 \\\\times \\\\frac{\\\\sqrt{3}}{4} \\\\times 2^2 = 4\\\\sqrt{3}$. The cross-sectional area is calculated by finding the magnitude of the cross product of vectors parallel to the edges. After computing the cross-section area as 1, and recognizing that the plane divides the surface area of three faces equally due to symmetry, the total surface area of one piece is $1 + 2\\\\sqrt{3} = 2\\\\\\\\sqrt{3} + 1$.\\\"\\n}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 19416 - Correct: False\n",
      "\n",
      "Starting problem test/number_theory/203.json, 310/500\n",
      "Correct Solution:  14\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{14}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 6771 - Correct: True\n",
      "\n",
      "Starting problem test/algebra/1842.json, 311/500\n",
      "Correct Solution:  49\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The simplified value is \\\\boxed{49}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 736 - Correct: True\n",
      "\n",
      "Starting problem test/number_theory/911.json, 312/500\n",
      "Correct Solution:  3\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The value of $n$ is \\\\boxed{3}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 1577 - Correct: True\n",
      "\n",
      "Starting problem test/intermediate_algebra/1714.json, 313/500\n",
      "Correct Solution:  (5,\\infty)\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{(5, \\\\infty)}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 1409 - Correct: True\n",
      "\n",
      "Starting problem test/prealgebra/1423.json, 314/500\n",
      "Correct Solution:  12\\pi\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The unicycle's speed is calculated by multiplying the circumference of the wheel by the number of revolutions per second. The circumference is $2\\\\pi \\\\times 9 = 18\\\\pi$ inches. With 2 revolutions every 3 seconds, the speed is $18\\\\pi \\\\times \\\\frac{2}{3} = 12\\\\pi$ inches per second. The answer is \\\\boxed{12\\\\pi}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 825 - Correct: True\n",
      "\n",
      "Starting problem test/geometry/1108.json, 315/500\n",
      "Correct Solution:  (2,4)\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The resulting point is \\\\boxed{(2, 4)}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 500 - Correct: True\n",
      "\n",
      "Starting problem test/algebra/791.json, 316/500\n",
      "Correct Solution:  41\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The answer is \\\\boxed{41}\"\n",
      "  }\n",
      "]\n",
      "\tCompleted Decomposition Inference and Analysis - Tokens: 1435 - Correct: True\n",
      "\n",
      "Starting problem test/algebra/276.json, 317/500\n",
      "Correct Solution:  12\n",
      "Initial JSON decode failed: Invalid \\escape: line 4 column 124 (char 166)\n",
      "Raw JSON string (repr): '{\\n    \"type\": \"COMPLETED\",\\n    \"level\": 0,\\n    \"result\": \"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\\\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\\\\\boxed{12}\"\\n}'\n",
      "Sanitized JSON decode failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "Malformed JSON string: {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\boxed{12}\"\n",
      "}\n",
      "Initial JSON decode failed: Invalid \\escape: line 4 column 124 (char 166)\n",
      "Raw JSON string (repr): '{\\n    \"type\": \"COMPLETED\",\\n    \"level\": 0,\\n    \"result\": \"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\\\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\\\\\boxed{12}\"\\n}'\n",
      "Sanitized JSON decode failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "Malformed JSON string: {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\boxed{12}\"\n",
      "}\n",
      "Initial JSON decode failed: Invalid \\escape: line 4 column 124 (char 166)\n",
      "Raw JSON string (repr): '{\\n    \"type\": \"COMPLETED\",\\n    \"level\": 0,\\n    \"result\": \"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\\\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\\\\\boxed{12}\"\\n}'\n",
      "Sanitized JSON decode failed: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)\n",
      "Malformed JSON string: {\n",
      "    \"type\": \"COMPLETED\",\n",
      "    \"level\": 0,\n",
      "    \"result\": \"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\boxed{12}\"\n",
      "}\n",
      "ERROR: Invalid JSON was produced by the model, exiting current inference.\n",
      "## Decomposition Inference ##\n",
      " [\n",
      "  {\n",
      "    \"type\": \"ERROR\",\n",
      "    \"level\": 0,\n",
      "    \"message\": \"INVALID JSON FORMATTING\",\n",
      "    \"raw\": \"{\\n    \\\"type\\\": \\\"COMPLETED\\\",\\n    \\\"level\\\": 0,\\n    \\\"result\\\": \\\"The expression $10x^2 - x - 24$ factors to $(5x - 8)(2x + 3)$, so $A = 5$, $B = 2$. Therefore, $AB + B = (5 \\\\cdot 2) + 2 = 10 + 2 = 12$. The answer is \\\\\\\\boxed{12}\\\"\\n}\"\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 869 column 1 (char 4774)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[158]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Print Decomposition Inference for Monitoring\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33m## Decomposition Inference ##\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, accumulated_inference)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m extracted_answer = \u001b[43mextract_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompleted_block\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopenrouter_client\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m resp_dict[\u001b[33m'\u001b[39m\u001b[33mdecomp_extracted_answer\u001b[39m\u001b[33m'\u001b[39m] = extracted_answer\n\u001b[32m     22\u001b[39m resp_dict[\u001b[33m'\u001b[39m\u001b[33mdecomp_correct\u001b[39m\u001b[33m'\u001b[39m] = grader.grade_answer(extracted_answer, row[\u001b[33m'\u001b[39m\u001b[33manswer\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[157]\u001b[39m\u001b[32m, line 160\u001b[39m, in \u001b[36mextract_answer\u001b[39m\u001b[34m(answer, client)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m# Default to model extraction, if regex fails\u001b[39;00m\n\u001b[32m    156\u001b[39m     extraction_prompt = \u001b[33m'''\u001b[39m\u001b[33m \u001b[39m\n\u001b[32m    157\u001b[39m \u001b[33m        Extract the contents of the final \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mboxed\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m and return the value, and only this value.\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[33m    \u001b[39m\u001b[33m'''\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     completion = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqwen/qwen-2.5-7b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextraction_prompt\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m completion.choices[\u001b[32m0\u001b[39m].message.content\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/resources/chat/completions/completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/_base_client.py:1039\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/_base_client.py:1121\u001b[39m, in \u001b[36mSyncAPIClient._process_response\u001b[39m\u001b[34m(self, cast_to, options, response, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(response.request.headers.get(RAW_RESPONSE_HEADER)):\n\u001b[32m   1119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, api_response)\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi_response\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/_response.py:323\u001b[39m, in \u001b[36mAPIResponse.parse\u001b[39m\u001b[34m(self, to)\u001b[39m\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_sse_stream:\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m.read()\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m parsed = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto\u001b[49m\u001b[43m=\u001b[49m\u001b[43mto\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_given(\u001b[38;5;28mself\u001b[39m._options.post_parser):\n\u001b[32m    325\u001b[39m     parsed = \u001b[38;5;28mself\u001b[39m._options.post_parser(parsed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/openai/_response.py:265\u001b[39m, in \u001b[36mBaseAPIResponse._parse\u001b[39m\u001b[34m(self, to)\u001b[39m\n\u001b[32m    260\u001b[39m     \u001b[38;5;66;03m# If the API responds with content that isn't JSON then we just return\u001b[39;00m\n\u001b[32m    261\u001b[39m     \u001b[38;5;66;03m# the (decoded) text without performing any parsing so that you can still\u001b[39;00m\n\u001b[32m    262\u001b[39m     \u001b[38;5;66;03m# handle the response however you need to.\u001b[39;00m\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.text  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m data = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._client._process_response_data(\n\u001b[32m    268\u001b[39m     data=data,\n\u001b[32m    269\u001b[39m     cast_to=cast_to,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    270\u001b[39m     response=response,\n\u001b[32m    271\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/site-packages/httpx/_models.py:832\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    831\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjson\u001b[39m(\u001b[38;5;28mself\u001b[39m, **kwargs: typing.Any) -> typing.Any:\n\u001b[32m--> \u001b[39m\u001b[32m832\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjsonlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/json/decoder.py:345\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    341\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    342\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    343\u001b[39m \n\u001b[32m    344\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    346\u001b[39m     end = _w(s, end).end()\n\u001b[32m    347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/nlp/lib/python3.13/json/decoder.py:363\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    361\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 869 column 1 (char 4774)"
     ]
    }
   ],
   "source": [
    "df_list, count = [], 1\n",
    "\n",
    "for row in ds['test']:\n",
    "    print(f\"Starting problem {row['unique_id']}, {count}/500\")\n",
    "    \n",
    "    resp_dict = {'problem': row['problem'], 'answer': row['answer']}\n",
    "    problem = row['problem']\n",
    "\n",
    "    print(\"Correct Solution: \", row['answer'])\n",
    "\n",
    "    ## forkJoin Inference/Analysis ##\n",
    "    forkJoin_question = create_math500_prompt(problem, True)\n",
    "    completed_block, accumulated_inference, token_usage = llmForkJoin(forkJoin_question, client=openrouter_client, model=model)\n",
    "    resp_dict['decomp_inference'] = accumulated_inference\n",
    "    resp_dict['decomp_tokens'] = token_usage\n",
    "\n",
    "    # Print Decomposition Inference for Monitoring\n",
    "    print('## Decomposition Inference ##\\n', accumulated_inference)\n",
    "\n",
    "    extracted_answer = extract_answer(completed_block, openrouter_client)\n",
    "    resp_dict['decomp_extracted_answer'] = extracted_answer\n",
    "    resp_dict['decomp_correct'] = grader.grade_answer(extracted_answer, row['answer'])\n",
    "\n",
    "    print(f\"\\tCompleted Decomposition Inference and Analysis - Tokens: {token_usage['total_output'] + token_usage['total_reasoning']} - Correct: {resp_dict['decomp_correct']}\\n\")\n",
    "\n",
    "    # ## Baseline Inference/Analysis ##\n",
    "    # baseline_question = create_math500_prompt(problem, False)\n",
    "    # baseline_inference, baseline_token_usage = get_baseline_stats(baseline_question, client=openrouter_client, model=model)\n",
    "    # resp_dict['baseline_inference'] = baseline_inference\n",
    "    # resp_dict['baseline_tokens'] = baseline_token_usage\n",
    "\n",
    "    # baseline_extracted_answer = extract_answer(baseline_inference, openrouter_client)\n",
    "    # resp_dict['baseline_extracted_answer'] = baseline_extracted_answer\n",
    "    # resp_dict['baseline_correct'] = grader.grade_answer(baseline_extracted_answer, row['answer'])\n",
    "\n",
    "    # print(f\"\\tCompleted Baseline Inference and Analysis - Tokens: {baseline_token_usage['total_output'] + baseline_token_usage['total_reasoning']} - Correct: {resp_dict['baseline_correct']}\")\n",
    "    \n",
    "    # Append to df_list\n",
    "    df_list.append(resp_dict)\n",
    "\n",
    "    # Increment tally\n",
    "    count += 1\n",
    "\n",
    "    # Save every 25 rows\n",
    "    if count % 25 == 0:\n",
    "        partial_df = pd.DataFrame(df_list)\n",
    "        partial_df.to_csv('results.csv')\n",
    "\n",
    "        # Clear jupyter Output\n",
    "        clear_output(wait=False)\n",
    "\n",
    "df = pd.DataFrame(df_list)\n",
    "df.to_csv('results.csv')\n",
    "\n",
    "## Note: Saved until 299/500 - restart from 300/500 [test/geometry/1097.json]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd47249",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d4585266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"results_0_299.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e4b171ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  0.8729096989966555\n"
     ]
    }
   ],
   "source": [
    "## Get the number of correct answers\n",
    "print(\"Correct: \", df[df[\"decomp_correct\"] == True].shape[0] / df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "58707b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR Percentage:  0.09698996655518395\n"
     ]
    }
   ],
   "source": [
    "err_df = df[df['decomp_inference'].str.contains(\"ERROR\")]\n",
    "print(\"ERROR Percentage: \", err_df.shape[0] / df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15bc014",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
